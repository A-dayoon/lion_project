{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 1. Korean-drama set\n",
    "### 1) 데이터 로드 및 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1752 entries, 0 to 1751\n",
      "Data columns (total 17 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   kdrama_id     1752 non-null   object \n",
      " 1   drama_name    1752 non-null   object \n",
      " 2   year          1752 non-null   int64  \n",
      " 3   director      1036 non-null   object \n",
      " 4   screenwriter  959 non-null    object \n",
      " 5   country       1752 non-null   object \n",
      " 6   type          1752 non-null   object \n",
      " 7   tot_eps       1752 non-null   int64  \n",
      " 8   duration      1728 non-null   float64\n",
      " 9   start_dt      1752 non-null   object \n",
      " 10  end_dt        1752 non-null   object \n",
      " 11  aired_on      1520 non-null   object \n",
      " 12  org_net       1344 non-null   object \n",
      " 13  content_rt    1752 non-null   object \n",
      " 14  synopsis      1584 non-null   object \n",
      " 15  rank          1752 non-null   int64  \n",
      " 16  pop           1752 non-null   int64  \n",
      "dtypes: float64(1), int64(4), object(12)\n",
      "memory usage: 232.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"korean_drama.csv\")\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>tot_eps</th>\n",
       "      <th>duration</th>\n",
       "      <th>rank</th>\n",
       "      <th>pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1752.000000</td>\n",
       "      <td>1752.000000</td>\n",
       "      <td>1728.000000</td>\n",
       "      <td>1752.000000</td>\n",
       "      <td>1752.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2019.006849</td>\n",
       "      <td>18.996005</td>\n",
       "      <td>2149.791667</td>\n",
       "      <td>22247.869292</td>\n",
       "      <td>22153.746575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.317455</td>\n",
       "      <td>25.618394</td>\n",
       "      <td>1532.133619</td>\n",
       "      <td>27688.839480</td>\n",
       "      <td>37776.993814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2015.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2017.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>720.000000</td>\n",
       "      <td>2441.500000</td>\n",
       "      <td>915.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2019.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>6265.500000</td>\n",
       "      <td>3698.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2021.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>3600.000000</td>\n",
       "      <td>49204.500000</td>\n",
       "      <td>12086.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2023.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>9180.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              year      tot_eps     duration          rank           pop\n",
       "count  1752.000000  1752.000000  1728.000000   1752.000000   1752.000000\n",
       "mean   2019.006849    18.996005  2149.791667  22247.869292  22153.746575\n",
       "std       2.317455    25.618394  1532.133619  27688.839480  37776.993814\n",
       "min    2015.000000     1.000000    60.000000      9.000000      1.000000\n",
       "25%    2017.000000     8.000000   720.000000   2441.500000    915.750000\n",
       "50%    2019.000000    12.000000  1800.000000   6265.500000   3698.500000\n",
       "75%    2021.000000    16.000000  3600.000000  49204.500000  12086.250000\n",
       "max    2023.000000   150.000000  9180.000000  99999.000000  99999.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kdrama_id         0\n",
       "drama_name        0\n",
       "year              0\n",
       "director        716\n",
       "screenwriter    793\n",
       "country           0\n",
       "type              0\n",
       "tot_eps           0\n",
       "duration         24\n",
       "start_dt          0\n",
       "end_dt            0\n",
       "aired_on        232\n",
       "org_net         408\n",
       "content_rt        0\n",
       "synopsis        168\n",
       "rank              0\n",
       "pop               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 데이터 전처리\n",
    "#### 결측치 처리\n",
    "- 'director' / 'screenwriter' / 'org_net' column의 결측치 제거\n",
    "- https://mydramalist.com 사이트에서 드라마 제목 검색 후 각 항목 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드라마명 중 한글 제거\n",
    "df1['drama_name'] = df1['drama_name'].str.replace(r'[가-힣]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요없는 열 삭제\n",
    "df1_filtered = df1[['drama_name', 'year', 'director', 'screenwriter',\n",
    "       'tot_eps', 'duration', 'start_dt', 'org_net', 'content_rt', 'rank', 'pop']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'director' / 'screenwriter' / 'org_net' column 중 결측치가 하나라도 있는 행 모두 추출\n",
    "unk = df1_filtered[df1_filtered.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링\n",
    "drama_names = unk[\"drama_name\"]  \n",
    "\n",
    "results = []\n",
    "\n",
    "for drama_name in drama_names:\n",
    "    url = f\"https://mydramalist.com/search?q={drama_name.replace(' ', '+')}\" \n",
    "    response = requests.get(url)\n",
    "\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # 검색 결과에서 첫 번째 드라마 클릭\n",
    "    element = soup.select_one(\".text-primary.title a\")\n",
    "    if element:\n",
    "        drama_page_url = \"https://mydramalist.com\" + element['href']\n",
    "        drama_response = requests.get(drama_page_url)\n",
    "        drama_soup = BeautifulSoup(drama_response.content, 'html.parser')\n",
    "\n",
    "        # Director와 Screenwriter 찾기\n",
    "        director, screenwriter, org_net = None, None, None\n",
    "        directors, screenwriters = [], []\n",
    "\n",
    "        if drama_soup.body:\n",
    "            # 'Screenwriter & Director' \n",
    "            combined_tag = drama_soup.find('b', text=lambda t: t and 'Screenwriter' in t and 'Director' in t)\n",
    "            if combined_tag:\n",
    "                # 'Screenwriter & Director'\n",
    "                combined_names = combined_tag.find_next_siblings('a')\n",
    "                for name in combined_names:\n",
    "                    directors.append(name.text)  \n",
    "                    screenwriters.append(name.text)  \n",
    "\n",
    "            # 'Director' \n",
    "            director_tag = drama_soup.find('b', text='Director:')\n",
    "            if director_tag:\n",
    "                director_name = director_tag.find_next('a').text\n",
    "                directors.append(director_name)  \n",
    "\n",
    "            # 'Screenwriter' \n",
    "            screenwriter_tag = drama_soup.find('b', text='Screenwriter:')\n",
    "            if screenwriter_tag:\n",
    "                screenwriter_name = screenwriter_tag.find_next('a').text\n",
    "                screenwriters.append(screenwriter_name)  \n",
    "\n",
    "            # 'Original Network' \n",
    "            org_net_tag = drama_soup.find('b', text='Original Network:')\n",
    "            if org_net_tag:\n",
    "                org_net = org_net_tag.find_next('a').text  \n",
    "\n",
    "        # 결과 저장\n",
    "        result = {\n",
    "            \"Drama Name\": drama_name, \n",
    "            \"Director\": ', '.join(directors) if directors else None, \n",
    "            \"Screenwriter\": ', '.join(screenwriters) if screenwriters else None,\n",
    "            \"Original Network\": org_net  \n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "# results_df.to_csv('added_data1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.columns = ['drama_name', 'director', 'screenwriter', 'org_net']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원 데이터에 크롤링된 데이터 취합\n",
    "merged_df =df1_filtered.merge(results_df[['drama_name', 'director', 'screenwriter','org_net']], on='drama_name', how='left', suffixes=('', '_from_results'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 행 별 결측치에 크롤링된 값 채워넣기\n",
    "merged_df['director'] = merged_df['director'].combine_first(merged_df['director_from_results'])\n",
    "merged_df['screenwriter'] = merged_df['screenwriter'].combine_first(merged_df['screenwriter_from_results'])\n",
    "merged_df['org_net'] = merged_df['org_net'].combine_first(merged_df['org_net_from_results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요한 칼럼만 추출\n",
    "merged_df = merged_df[['drama_name', 'year', 'director', 'screenwriter', 'tot_eps', 'duration',\n",
    "       'start_dt', 'org_net', 'content_rt', 'rank', 'pop']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터타입 및 형태 통합\n",
    "- 'start_dt' 칼럼 데이터타입 변환 및 형태 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 먼저 ISO 형식 처리\n",
    "merged_df['date'] = pd.to_datetime(merged_df['start_dt'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "# 이후 나머지 형식을 처리하고 NaT 값 교체\n",
    "merged_df['date'] = merged_df['date'].combine_first(\n",
    "    pd.to_datetime(merged_df['start_dt'], format='%b %d, %Y', errors='coerce')\n",
    ")\n",
    "\n",
    "# 최종적으로 YYYY-MM-DD 형식으로 통일한 후 YYYY-MM 값만 'date'칼럼에 저장\n",
    "merged_df['date'] = merged_df['date'].dt.strftime('%Y-%m-%d').str[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#날짜 형이 다른 경우\n",
    "# 변환 함수 정의\n",
    "def convert_to_year_month(date_str):\n",
    "    if pd.isna(date_str):\n",
    "        return None\n",
    "    \n",
    "    # 공백 및 쉼표 제거\n",
    "    date_str = date_str.replace(',', '').strip()\n",
    "    \n",
    "    # 년-월 형식으로 변환\n",
    "    if len(date_str) == 4:  # 연도만 있는 경우\n",
    "        return f\"{date_str}-01\"  # 기본 월은 01로 설정\n",
    "    \n",
    "    try:\n",
    "        # 날짜로 변환\n",
    "        date_obj = pd.to_datetime(date_str)\n",
    "        return date_obj.to_period('M').strftime('%Y-%m')\n",
    "    except Exception as e:\n",
    "        return None  # 변환할 수 없는 경우 None 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#날짜형 이상한 행 추출해 변환된 값 적용\n",
    "date_na_val = merged_df[merged_df['date'].isna()]['start_dt'].str.split('-').str[0]\n",
    "date_na_val = date_na_val.apply(convert_to_year_month)\n",
    "merged_df.loc[merged_df['date'].isna(), 'date'] = date_na_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'director' / 'screenwriter' 칼럼 양식 통일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['director'] = merged_df['director'].astype(str).str.replace(r\"[\\[\\]\\\"']\", \"\", regex=True)\n",
    "merged_df['screenwriter'] = merged_df['screenwriter'].astype(str).str.replace(r\"[\\[\\]\\\"']\", \"\", regex=True)\n",
    "\n",
    "merged_df.loc[:, 'director'] = merged_df['director'].replace({'None': np.nan})\n",
    "merged_df.loc[:, 'screenwriter'] = merged_df['screenwriter'].replace({'None': np.nan})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 칼럼 범주화 및 재그룹화\n",
    "- 'content_rt' 칼럼 재그룹화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['content_rt'] = merged_df['content_rt'].replace({\n",
    "    'Not Yet Rated': 'UNK',\n",
    "    '15+ - Teens 15 or older': '15',\n",
    "    '18+ Restricted (violence & profanity)': '18',\n",
    "    '13+ - Teens 13 or older': '13',\n",
    "    'G - All Ages': 'ALL',  \n",
    "    'R - Restricted Screening (nudity & violence)': '18' \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'org_net' 칼럼 범주화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['org_net'] = merged_df['org_net'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['new_org_net'] = merged_df['org_net']\n",
    "merged_df['new_org_net'] = merged_df['new_org_net'].fillna('기타')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcast_keywords = [\n",
    "    'mbc', 'sbs', 'ena', 'jtbc', 'tvn', 'channel a',\n",
    "    'kbs', 'tv chosun', 'obs', 'ebs', 'ocn', 'mbn',\n",
    "    'drama cube', 'toonniverse', 'dramax', 'mnet',\n",
    "    'e-channel', 'qtv'\n",
    "]\n",
    "\n",
    "# new_org_net 칼럼의 특정 단어가 포함된 경우 'broadcast'로 변경\n",
    "merged_df['new_org_net'] = merged_df['new_org_net'].apply(\n",
    "    lambda x: 'broadcast' if isinstance(x, str) and any(keyword in x.lower() for keyword in broadcast_keywords) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ott 그룹 분류\n",
    "merged_df['new_org_net'] = merged_df['new_org_net'].apply(\n",
    "    lambda x: 'ott' if isinstance(x, str) and not any(word in x for word in ['broadcast', '기타', 'naver', 'daum']) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# web 그룹 분류\n",
    "merged_df['new_org_net'] = merged_df['new_org_net'].apply(\n",
    "    lambda x: 'web' if isinstance(x, str) and ('naver' in x or 'daum' in x) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기타 - 'duration' 칼럼 초 > 분 단위로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['duration'] = merged_df['duration']/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Review dataset\n",
    "### 1) 평점 기준 단어 빈도표 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tagging_filter(text):\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = [token.text for token in doc if token.pos_ in [\"ADJ\", \"NOUN\"]] \n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['filtered_review_text'] = df2['review_text'].apply(lambda x: pos_tagging_filter(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변경할 단어와 대체할 단어를 딕셔너리로 정의\n",
    "replace_dict = {'characters': 'character', 'episodes': 'episode', 'ep': 'episode', 'actors': 'actor', 'scenes':'scene', 'writers':'writer'}\n",
    "\n",
    "df2['filtered_review_text'] = df2['filtered_review_text'].apply(\n",
    "    lambda word_list: [replace_dict.get(word, word) for word in word_list] if isinstance(word_list, list) else []\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_df = df2[df2['overall_score']>=5]\n",
    "bad_df = df2[df2['overall_score']<5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_df['filtered_review_text'] = good_df['filtered_review_text'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "exclude_words = ['drama', 'dramas', 'show', 'other', 'more' ,'way', 'first', 'lead', 'bit', 'much','things','little', 'one','thing', 'last', 'own','whole', 'better',\n",
    "                  'leads', 'time', 'times', 'most', 'end', 'many', 'main', 'lot', 'second', 'moment', 'moments', 'people', 'person', 'part', 'duo', 'real', 'point',\n",
    "                  'side', 'fact', 'few', 'life', 'good', 'series', 'same','season', 'episode', 'scene', 'love','character', 'story']  # 제외하고 싶은 단어들 리스트\n",
    "\n",
    "# 필터링된 단어들만 카운트\n",
    "all_words = [word for sublist in good_df['filtered_review_text'] for word in sublist if word not in exclude_words]\n",
    "word_count = Counter(all_words)\n",
    "good_count_df = pd.DataFrame(word_count.items(), columns=['word', 'count'])\n",
    "\n",
    "good_count_df = good_count_df.sort_values(by='count', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_df['filtered_review_text'] = bad_df['filtered_review_text'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "# 필터링된 단어들만 카운트\n",
    "all_words = [word for sublist in bad_df['filtered_review_text'] for word in sublist if word not in exclude_words]\n",
    "word_count = Counter(all_words)\n",
    "bad_count_df = pd.DataFrame(word_count.items(), columns=['word', 'count'])\n",
    "\n",
    "bad_count_df = bad_count_df.sort_values(by='count', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_count_df['sep']='good'\n",
    "bad_count_df['sep']='bad'\n",
    "\n",
    "word_count_df = pd.concat([good_count_df, bad_count_df], axis=0, ignore_index=True)\n",
    "\n",
    "word_count_df.to_csv('review_word_count_fin.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 신규 데이터프레임 생성\n",
    "### 1) Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3= pd.read_csv('wiki_actors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 컬럼 정리(각 데이터셋에 필요없는 컬럼들 정리)\n",
    "df3 = df3.drop(columns= ['actor_id', 'character_name', 'role'])\n",
    "df2 = df2.drop(columns=['user_id', 'review_text', 'ep_watched', 'n_helpful'])\n",
    "\n",
    "# df3[drama_name] 항목에 텍스트 조정\n",
    "df3['drama_name'] = df3['drama_name'].str.replace(r'[가-힣]', '', regex=True)\n",
    "\n",
    "# 데이터프레임 병합 (drama_name과 title을 기준으로 병합)\n",
    "actor_merged_df = pd.merge(df3, df2, left_on='drama_name', right_on='title', how='left')\n",
    "\n",
    "# title 열 삭제 (drama_name과 같은 값이므로 중복 제거)\n",
    "actor_merged_df = actor_merged_df.drop(columns=['title'])\n",
    "\n",
    "# actor_name과 drama_name으로 그룹화하고 나머지 평점의 평균 계산\n",
    "actor_grouped_df = actor_merged_df.groupby(['actor_name', 'drama_name']).mean().reset_index()\n",
    "\n",
    "# 모든 평점 컬럼의 값을 소수점 첫 번째 자리로 반올림\n",
    "actor_grouped_df = actor_grouped_df.round({\n",
    "    'story_score': 1,\n",
    "    'acting_cast_score': 1,\n",
    "    'music_score': 1,\n",
    "    'rewatch_value_score': 1,\n",
    "    'overall_score': 1\n",
    "})\n",
    "\n",
    "#결측치 제거\n",
    "actor_grouped_df = actor_grouped_df.dropna()\n",
    "actor_grouped_df.info()\n",
    "\n",
    "\n",
    "#csv 파일로 저장\n",
    "actor_grouped_df.to_csv('actor_grouped_around_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Director"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "director_df = merged_df.drop(columns= ['year', 'screenwriter', 'tot_eps','duration','screenwriter','org_net','content_rt','date'])\n",
    "\n",
    "# 행분리 (director 기준)\n",
    "merged_df_explode = director_df.assign(director=merged_df.director.str.split(',')).explode('director')\n",
    "# 데이터프레임 병합 (drama_name과 title을 기준)\n",
    "director_merged_df = pd.merge(merged_df, df2, left_on='drama_name', right_on='title', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복 값 title 제거 ( = drama_name 과 동일)\n",
    "director_merged_df = director_merged_df.drop(columns=['title'])\n",
    "# director와 drama_name으로 그룹화하고 나머지 평점의 평균 계산\n",
    "director_grouped_df = director_merged_df.groupby(['director', 'drama_name']).mean().reset_index()\n",
    "\n",
    "# rank와 pop 칼럼은 정수형으로 변환하고, 나머지 평점 관련 칼럼은 소수점 첫째 자리까지 반올림\n",
    "director_grouped_df['rank'] = director_grouped_df['rank'].round(0).astype(int)\n",
    "director_grouped_df['pop'] = director_grouped_df['pop'].round(0).astype(int)\n",
    "\n",
    "# 나머지 평점 칼럼은 소수점 첫째 자리까지 반올림\n",
    "director_grouped_df[['story_score', 'acting_cast_score', 'music_score', 'rewatch_value_score', 'overall_score']] = director_grouped_df[['story_score', 'acting_cast_score', 'music_score', 'rewatch_value_score', 'overall_score']].round(1)\n",
    "# 각 행에 결측치가 하나라도 있는 경우 제거\n",
    "director_grouped_df = director_grouped_df.dropna(how='any')\n",
    "\n",
    "# CSV 파일로 저장\n",
    "director_grouped_df.to_csv('director_grouped.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('new_org_drama.csv')\n",
    "df_exploded = df.assign(screenwriter=df['screenwriter'].str.split(', ')).explode('screenwriter')\n",
    "df_merged = df2.groupby('title')[['story_score','acting_cast_score','music_score','rewatch_value_score','overall_score']].mean().reset_index()\n",
    "writer_merged_df = pd.merge(df_exploded, df_merged, left_on='drama_name', right_on='title', how='left')\n",
    "\n",
    "writer_merged_df = writer_merged_df[['drama_name','screenwriter',\n",
    "       'story_score', 'acting_cast_score', 'music_score',\n",
    "       'rewatch_value_score', 'overall_score']]\n",
    "\n",
    "writer_merged_df = writer_merged_df.round({\n",
    "    'story_score': 1,\n",
    "    'acting_cast_score': 1,\n",
    "    'music_score': 1,\n",
    "    'rewatch_value_score': 1,\n",
    "    'overall_score': 1\n",
    "})\n",
    "\n",
    "writer_merged_df = writer_merged_df.dropna()\n",
    "writer_merged_df.to_csv('writer_finish_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 사용자 특성 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"CI_MOBILE_OTT_WTCHNG_GENRE_ND_USR_CHARTR_INFO_202305.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['RESPOND_ID', 'EXAMIN_BEGIN_DE'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['국내영화',\n",
    "              '해외영화',\n",
    "              '국내드라마',\n",
    "              '해외드라마',\n",
    "              '예능프로그램',\n",
    "              '다큐멘터리',\n",
    "              '애니메이션',\n",
    "              '생방송',\n",
    "              '키즈',\n",
    "              '성별',\n",
    "              '연령대',\n",
    "              '결혼여부',\n",
    "              '가구소득정도',\n",
    "              '직업명',\n",
    "              '거주지역']\n",
    "\n",
    "df[['국내영화','해외영화','국내드라마','해외드라마','예능프로그램','다큐멘터리','애니메이션','생방송','키즈']] = df[['국내영화','해외영화','국내드라마','해외드라마','예능프로그램','다큐멘터리','애니메이션','생방송','키즈']].replace({'Y': 1, 'N': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['이용여부'] = df[['국내영화','해외영화','국내드라마','해외드라마','예능프로그램','다큐멘터리','애니메이션','생방송','키즈']].apply(lambda row: 1 if row.sum() > 0 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지역 그룹화\n",
    "region_mapping = {\n",
    "    '서울': '수도권',\n",
    "    '경기': '수도권',\n",
    "    '인천': '수도권',\n",
    "    '충남': '충청도',\n",
    "    '충북': '충청도',\n",
    "    '대전': '충청도',\n",
    "    '세종': '충청도',\n",
    "    '경남': '경상도',\n",
    "    '경북': '경상도',\n",
    "    '부산': '경상도',\n",
    "    '대구': '경상도',\n",
    "    '울산': '경상도',\n",
    "    '광주': '전라도',\n",
    "    '전북': '전라도',\n",
    "    '전남': '전라도',\n",
    "    '제주': '제주',\n",
    "    '강원': '강원도'\n",
    "}\n",
    "\n",
    "# 새로운 지역 범주로 변환\n",
    "df['지역권'] = df['거주지역'].replace(region_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 중위연령"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.read_csv('인구.csv', encoding=\"ANSI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df = pop[pop['인구구조, 부양비별(1)'] == '중위연령(세)'][['시도별(1)','2024']][1:]\n",
    "pop_df.columns = ['지역', '중위연령']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df['지역'] = pop_df['지역'].replace({\n",
    "    '서울특별시' : '서울',\n",
    "    '부산광역시':'부산',\n",
    "    '대구광역시':'대구',\n",
    "    '인천광역시':'인천',\n",
    "    '광주광역시':'광주',\n",
    "    '대전광역시':'대전',\n",
    "    '울산광역시':'울산',\n",
    "    '세종특별자치시':'세종',\n",
    "    '경기도':'경기',\n",
    "    '강원도':'강원',\n",
    "    '충청북도':'충북',\n",
    "    '충청남도':'충남',\n",
    "    '전라북도':'전북',\n",
    "    '전라남도':'전남',\n",
    "    '경상북도':'경북',\n",
    "    '경상남도':'경남',\n",
    "    '제주특별자치도':'제주'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin = pd.merge(df, pop_df, left_on='거주지역', right_on='지역', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin = df_fin[['국내드라마','연령대', '거주지역', '이용여부', '소득범주', '지역권', '지역', '중위연령']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin.to_csv('ott_watcher_fin.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
